{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import pyrealsense2.pyrealsense2 as rs\n",
    "sift_detector = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "\n",
    "profile = pipeline.start(config)\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "if depth_sensor.supports(rs.option.depth_units):\n",
    "    depth_sensor.set_option(rs.option.depth_units,0.001)\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "align = rs.align(rs.stream.color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world axis origin locate at the bottom ground of the camera, the depth camera is located (-30, 125, 0)\n",
    "# camera: x: → y: ↓ z: o\n",
    "# world: x: → y: ↑ z: x (using the cooridinates of vpython)\n",
    "# need to rotate x: 180 deg, y: 0 deg, z: 0 deg, translate (-30, 125, 0) (mm)\n",
    "camera_extrinsics = rs.extrinsics()\n",
    "camera_extrinsics.rotation = [float(x) for x in [1, 0, 0, 0, np.cos(np.pi), -np.sin(np.pi), 0, np.sin(np.pi), np.cos(np.pi)]]\n",
    "camera_extrinsics.translation = [-0.03, 0.125, 0.5] # specified in meter\n",
    "bbox = [[240, 480], [719, 800]]\n",
    "middle_pixel = ((240 + 719) // 2, (480 + 800) // 2)\n",
    "pixels = [[middle_pixel[0] + (-2 + i) * 100, middle_pixel[1] + (-2 + i) * 100] for i in range(5)]\n",
    "while True:\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    if not frames:\n",
    "        break\n",
    "\n",
    "    aligned_frames = align.process(frames)   \n",
    "    depth_frame = aligned_frames.get_depth_frame() \n",
    "    color_frame = aligned_frames.get_color_frame()\n",
    "    aligned_intrinsic = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "    frame = np.asanyarray(color_frame.get_data())\n",
    "    world_axis_points = []\n",
    "    for pt in pixels:\n",
    "        x, y = pt\n",
    "        d = depth_frame.get_distance(y, x) # input y, x\n",
    "        camera_axis_point = rs.rs2_deproject_pixel_to_point(aligned_intrinsic, (y, x), d) # input y, x\n",
    "        world_axis_point = rs.rs2_transform_point_to_point(camera_extrinsics, camera_axis_point)\n",
    "        cv2.circle(frame, (y, x), radius=5, color=(0, 255, 255), thickness=-1)\n",
    "        world_axis_points.append(world_axis_point)\n",
    "\n",
    "    print(\"                                         \".join(map(lambda x: str([\"{:2f}\".format(i*1000) for i in x]), world_axis_points)), end='\\r')\n",
    "\n",
    "    cv2.rectangle(frame, (bbox[0][1], bbox[0][0]), (bbox[1][1], bbox[1][0]), color=(0, 255, 0), thickness=2)\n",
    "    cv2.circle(frame, (middle_pixel[1], middle_pixel[0]), radius=5, color=(0, 0, 255), thickness=-1)\n",
    "    cv2.putText(frame, \"Distance to middle box pixel: ({}, {}), World axis points of middle box pixel: ({:4f}, {:4f}, {:4f})\".format(middle_pixel[0], middle_pixel[1], \\\n",
    "                        world_axis_point[0], world_axis_point[1], world_axis_point[2]),\\\n",
    "                org=(20, 20), fontFace=cv2.FONT_HERSHEY_COMPLEX, thickness=2, fontScale=0.6, color=(0, 0, 0))\n",
    "    cv2.imshow(\"Realsense RGB\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('s') or key == ord('S'):\n",
    "        now = time.localtime(time.time())\n",
    "        y = str(now.tm_year)\n",
    "        m = str(now.tm_mon) if now.tm_mon > 9 else '0' + str(now.tm_mon)\n",
    "        h = str(now.tm_hour) if now.tm_hour > 9 else '0' + str(now.tm_hour)\n",
    "        u = str(now.tm_min) if now.tm_min > 9 else '0' + str(now.tm_min)\n",
    "        s = str(now.tm_sec) if now.tm_sec > 9 else '0' + str(now.tm_sec)\n",
    "        cv2.imwrite(\"{}{}{}{}{}_Kebuke.jpg\".format(y, m, h, u, s), frame)\n",
    "        \n",
    "    if key == 27:  # ESC key: quit program\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "    #\n",
    "        #\n",
    "            #\n",
    "                #\n",
    "\n",
    "\n",
    "['-107.581399', '-43.461908', '481.000036'],\n",
    "['-54.944925', '8.628501', '477.000028'],\n",
    "['-3.176244', '59.851333', '473.000020'],\n",
    "['47.419373', '109.501652', '466.000021'],\n",
    "# ['0.000000', '0.000000', '0.000000']\n",
    "\n",
    "['-137.581393', '168.461904', '18.999964'],\n",
    "['-84.944926', '116.371498', '22.999972'],\n",
    "['-33.176243', '65.148667', '26.999980'],\n",
    "['17.419374', '15.498348', '33.999979'],\n",
    "# ['-29.999999', '125.000000', '500.000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving features [kpts:list, des:ndarray, relative point to cup origin:list]\n",
    "fimg = cv2.imread(\"KEBUKE_feature/imgsrc/aging1.png\")\n",
    "\n",
    "# measured by ruler\n",
    "fwidth_mm = 12 / 9 * 10\n",
    "fheight_mm = 12 / 9 * 9.9\n",
    "fx_mm = 0 # middle\n",
    "fy_mm = 104 # middle\n",
    "fz_mm = -7.3 # middle\n",
    "\n",
    "fkpts_img, fdes_img = sift_detector.detectAndCompute(cv2.cvtColor(fimg, cv2.COLOR_BGR2GRAY), None)\n",
    "fkpts_pts = []\n",
    "f_relative_points = [] # world: x: → y: ↑ z: x\n",
    "fh, fw, _ = fimg.shape\n",
    "for fkpt in fkpts_img:\n",
    "    x, y = fkpt.pt\n",
    "    rx = fx_mm + fwidth_mm * (x - fw // 2) / fw\n",
    "    ry = fy_mm + fheight_mm * (y - fw // 2) / fw\n",
    "    rz = fz_mm * (y / (fh / 2))\n",
    "    fkpts_pts.append([x, y])\n",
    "    f_relative_points.append([rx, ry, rz])\n",
    "\n",
    "save = [fkpts_pts, fdes_img, f_relative_points]\n",
    "with open('KEBUKE_feature/aging1.pickle', 'wb') as f:\n",
    "    pickle.dump(save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt in fkpts_pts:\n",
    "    cv2.circle(fimg, [int(x) for x in pt], 1, (0, 0, 255))\n",
    "cv2.namedWindow(\"ouo\", cv2.WINDOW_KEEPRATIO)\n",
    "cv2.imshow(\"ouo\", fimg)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"Feature_with_keypoints.jpg\", fimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_detector = cv2.SIFT_create()\n",
    "img = cv2.imread(\"KEBUKE/202306154114_Kebuke.jpg\")\n",
    "aging = cv2.imread(\"KEBUKE_feature/imgsrc/aging1.png\")\n",
    "kpts_img, des_img = sift_detector.detectAndCompute(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), None)\n",
    "kpts_aging, des_aging = sift_detector.detectAndCompute(cv2.cvtColor(aging, cv2.COLOR_BGR2GRAY), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpts_bimg, des_bimg = sift_detector.detectAndCompute(cv2.GaussianBlur(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), ksize=(5, 5), sigmaX=0.7), None)\n",
    "kpts_baging, des_baging = sift_detector.detectAndCompute(cv2.GaussianBlur(cv2.cvtColor(aging, cv2.COLOR_BGR2GRAY), ksize=(5, 5), sigmaX=0.7), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "img2 = img.copy()\n",
    "bboxes = [[[425, 333], [655, 712]], [[360, 797], [719, 1019]]]\n",
    "bkpts = None\n",
    "bmatches = None\n",
    "bmatches_mask = None\n",
    "for bbox in bboxes:\n",
    "    x1, y1 = bbox[0]\n",
    "    x2, y2 = bbox[1]\n",
    "    cv2.rectangle(img2, (y1, x1), (y2, x2), color=(0, 255, 0), thickness=2)\n",
    "    kpts, des = sift_detector.detectAndCompute(cv2.cvtColor(img[x1:x2, y1:y2], cv2.COLOR_BGR2GRAY), None)\n",
    "    for i in range(len(kpts)):\n",
    "        y, x = kpts[i].pt\n",
    "        kpts[i].pt = (y + y1, x + x1)\n",
    "\n",
    "    matches = flann.knnMatch(des, des_aging, k=2)\n",
    "    # Need to draw only good matches, so create a mask\n",
    "    matchesMask = [[0,0] for i in range(len(matches))]\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            matchesMask[i]=[1,0]\n",
    "\n",
    "    if isinstance(bkpts, tuple):\n",
    "        for i in range(len(matches)):\n",
    "            for j in range(2):\n",
    "                matches[i][j].queryIdx += len(bkpts) \n",
    "        bkpts = tuple(list(bkpts) + list(kpts))\n",
    "        bmatches = tuple(list(bmatches) + list(matches))\n",
    "        bmatches_mask = bmatches_mask + matchesMask\n",
    "    else:\n",
    "        bkpts = kpts\n",
    "        bmatches = matches\n",
    "        bmatches_mask = matchesMask\n",
    "\n",
    "draw_params = dict(matchColor = (0,255,0),\n",
    "                singlePointColor = (255,0,0),\n",
    "                matchesMask = bmatches_mask,\n",
    "                flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "img2 = cv2.drawMatchesKnn(img2,bkpts,aging,kpts_aging,bmatches,None,**draw_params)\n",
    "\n",
    "cv2.namedWindow(\"ouo\", cv2.WINDOW_KEEPRATIO)\n",
    "cv2.imshow(\"ouo\", img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
